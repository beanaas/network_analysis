{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "with open('./links/2.txt', 'r') as file:\n",
    "    # Read and process each line\n",
    "    for line in file:\n",
    "        splitted = line.split(\" \")\n",
    "        n = int(splitted[0])\n",
    "        nprime = int(splitted[1])\n",
    "        links.append((n, nprime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "titles = {}\n",
    "with open('./titles/2.txt', 'r') as file:\n",
    "    # Read and process each line\n",
    "    for line in file:\n",
    "        counter+=1\n",
    "        titles[counter] = line\n",
    "degrees_in = {}\n",
    "degrees_out = {}\n",
    "\n",
    "for nnprime in links:\n",
    "    n = nnprime[0]\n",
    "    nprime = nnprime[1]\n",
    "\n",
    "    if(n in degrees_out.keys()):\n",
    "        degrees_out[n].append(nprime)\n",
    "    else:\n",
    "        degrees_out[n] = [nprime]\n",
    "\n",
    "    if(nprime in degrees_in.keys()):\n",
    "        degrees_in[nprime].append(n)\n",
    "    else:\n",
    "        degrees_in[nprime] = [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_degrees_in = {}\n",
    "num_degrees_out = {}\n",
    "for i in degrees_in:\n",
    "    num_degrees_in[i] = len(degrees_in[i])\n",
    "for i in degrees_out:\n",
    "    num_degrees_out[i] = len(degrees_out[i])\n",
    "sorted_degrees_in = dict(sorted(num_degrees_in.items(), key=lambda x: x[1], reverse=True))\n",
    "sorted_degrees_out = dict(sorted(num_degrees_out.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "node_ids_list1 = []\n",
    "node_ids_list2 = []\n",
    "\n",
    "normalized_in_degree = {}\n",
    "normalized_out_degree = {}\n",
    "\n",
    "\n",
    "for i in sorted_degrees_in:\n",
    "    node_ids_list1.append(i)\n",
    "    normalized_in_degree[i] = num_degrees_in[i]/(len(links))\n",
    "    if(i in sorted_degrees_out.keys()):\n",
    "        list1.append((degrees_in[i], degrees_out[i]))\n",
    "    else:\n",
    "        list1.append((degrees_in[i], []))\n",
    "\n",
    "for i in sorted_degrees_out:\n",
    "    normalized_out_degree[i] = num_degrees_out[i]/(len(links))\n",
    "    node_ids_list2.append(i)\n",
    "    if(i in sorted_degrees_in.keys()):\n",
    "        list2.append((degrees_in[i], degrees_out[i])) \n",
    "    else:\n",
    "        list2.append(([], degrees_out[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN DEGREES\n",
      "2007\n",
      " 0.007685 0.000254\n",
      "2008\n",
      " 0.006608 1.2e-05\n",
      "United_States\n",
      " 0.006596 1.2e-05\n",
      "United_Kingdom\n",
      " 0.00541 0.000218\n",
      "France\n",
      " 0.005156 0.001476\n",
      "OUT DEGREES\n",
      ".cf\n",
      " 0.003231 4.8e-05\n",
      "Book_of_Optics\n",
      " 0.003171 0.000242\n",
      "Bengali_language\n",
      " 0.002844 0.000351\n",
      "Dumfries,_VA\n",
      " 0.002759 1.2e-05\n",
      "Ahmad_Zarruq\n",
      " 0.002638 0.001404\n"
     ]
    }
   ],
   "source": [
    "print(\"IN DEGREES\")\n",
    "for node_id in node_ids_list1[:5]:\n",
    "    title = titles[node_id]\n",
    "    print(title, round(normalized_in_degree[node_id],6), round(normalized_out_degree[node_id],6))\n",
    "\n",
    "print(\"OUT DEGREES\")\n",
    "for node_id in node_ids_list2[:5]:\n",
    "    title = titles[node_id]\n",
    "    print(title, round(normalized_out_degree[node_id],6), round(normalized_in_degree[node_id],6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUB\n",
      ".cf\n",
      " 0.006991 0.0\n",
      "Book_of_Optics\n",
      " 0.006978 7.8e-05\n",
      "Bengali_language\n",
      " 0.006846 0.00014\n",
      "Erich_Schmidt_(archaeologist)\n",
      " 0.006811 1e-06\n",
      "1999_NATO_bombing_of_the_Federal_Republic_of_Yugoslavia\n",
      " 0.006803 4e-06\n",
      "AUTH\n",
      "Shams_Tabrizi\n",
      " 0.006591 0.000277\n",
      "Mahmud_Shabistari\n",
      " 0.00658 0.0003\n",
      "Al-Ghazali\n",
      " 0.006541 0.0\n",
      "Shahab_al-Din_Suhrawardi\n",
      " 0.006472 0.0\n",
      "Farid_al-Din_Attar\n",
      " 0.00646 0.0\n"
     ]
    }
   ],
   "source": [
    "def normalize(dictionary):\n",
    "    tot = sum(dictionary.values())\n",
    "    for key in dictionary.keys():\n",
    "        dictionary[key] = dictionary[key]/tot\n",
    "    return dictionary\n",
    "\n",
    "def get_new_hub_score(degrees_out, auths):\n",
    "    #iterate over all hubs to update\n",
    "    new_hub = {}\n",
    "    for hub_node in degrees_out.keys():\n",
    "        #gets all the nodes pointing to hub node\n",
    "        new_hub_score = 0\n",
    "        for auth_node in degrees_out[hub_node]:\n",
    "            new_hub_score += auths[auth_node]\n",
    "        new_hub[hub_node] = new_hub_score\n",
    "    return normalize(new_hub)\n",
    "\n",
    "def get_new_auth_score(degrees_in, hubs):\n",
    "    new_auth = {}\n",
    "    for auth_node in degrees_in.keys():\n",
    "        new_auth_score = 0\n",
    "        for out_node in degrees_in[auth_node]:\n",
    "            new_auth_score += hubs[out_node]\n",
    "        new_auth[auth_node] = new_auth_score\n",
    "    return normalize(new_auth)\n",
    "\n",
    "hubs = normalized_out_degree\n",
    "auths = normalized_in_degree\n",
    "\n",
    "for i in range(100):\n",
    "    hubs = get_new_hub_score(degrees_out, auths)\n",
    "    auths = get_new_auth_score(degrees_in, hubs)\n",
    "\n",
    "\n",
    "sorted_on_hub_score = dict(sorted(hubs.items(), key=lambda x: x[1], reverse=True))\n",
    "sorted_on_auth_score = dict(sorted(auths.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top5_hubs = list(sorted_on_hub_score.keys())[:5]\n",
    "top5_auths = list(sorted_on_auth_score.keys())[:5]\n",
    "print(\"HUB\")\n",
    "for i in top5_hubs:\n",
    "    if(i not in sorted_on_auth_score.keys()):\n",
    "        print(titles[i], round(sorted_on_hub_score[i],6), 0.00)\n",
    "    else:\n",
    "        print(titles[i], round(sorted_on_hub_score[i],6), round(sorted_on_auth_score[i],6))\n",
    "\n",
    "print(\"AUTH\")\n",
    "for i in top5_auths:\n",
    "    if(i not in sorted_on_hub_score.keys()):\n",
    "        print(titles[i], round(sorted_on_auth_score[i],6), 0.00)\n",
    "    else:\n",
    "        print(titles[i], round(sorted_on_auth_score[i],6), round(sorted_on_hub_score[i],6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUB\n",
      "United_States\n",
      " 0.007305 0.0\n",
      "United_Kingdom\n",
      " 0.005992 0.0\n",
      "France\n",
      " 0.00571 0.0\n",
      "Iran\n",
      " 0.005228 0.0\n",
      "Wikimedia_Commons\n",
      " 0.004946 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def get_eigenvector(degrees_in, centrality_in):\n",
    "    for node in degrees_in.keys():\n",
    "        centrality = 0\n",
    "        for node_in in degrees_in[node]:\n",
    "            if(node_in in centrality_in.keys()):\n",
    "                centrality += centrality_in[node_in]\n",
    "        centrality_in[i] = centrality\n",
    "    return centrality_in\n",
    "\n",
    "centrality_in = num_degrees_in\n",
    "        \n",
    "for i in range(200):\n",
    "    centrality_in = get_eigenvector(degrees_in, centrality_in)\n",
    "\n",
    "centrality_in = normalize(centrality_in)\n",
    "sorted_on_vector_score = dict(sorted(centrality_in.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "top5_centrality = list(sorted_on_vector_score.keys())[:5]\n",
    "print(\"HUB\")\n",
    "for i in top5_centrality:\n",
    "    print(titles[i], round(sorted_on_vector_score[i],6), 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      " 0.006334\n",
      "71\n",
      "United_States\n",
      " 0.006312\n",
      "2770\n",
      "2008\n",
      " 0.005851\n",
      "73\n",
      "France\n",
      " 0.005535\n",
      "946\n",
      "United_Kingdom\n",
      " 0.005324\n",
      "2765\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "cols, rows = zip(*[(i - 1, j - 1) for i, j in links])\n",
    "data = np.ones(len(rows), dtype=int)\n",
    "\n",
    "# Create the sparse matrix using coo_matrix\n",
    "size = len(list(titles.keys()))\n",
    "sparse_matrix = sp.coo_matrix((data, (rows, cols)), shape=(size, size), dtype=np.float64)\n",
    "\n",
    "# Calculate the eigenvector centrality\n",
    "eigen_value, eigen_vector = sp.linalg.eigs(sparse_matrix,k=1, which=\"LR\")  # Use transpose for right eigenvector\n",
    "eigen_vector = np.abs(eigen_vector.flatten())\n",
    "eigen_vector /= eigen_vector.sum()\n",
    "\n",
    "sorted_indices = np.argsort(eigen_vector)[::-1]\n",
    "\n",
    "# Get the values and indices of the first 5 elements\n",
    "top5_eigen = eigen_vector[sorted_indices[:5]]\n",
    "top5_eigen_indices = sorted_indices[:5]\n",
    "for i in top5_eigen_indices:\n",
    "    print(titles[i+1], round(eigen_vector[i],6))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      " 0.005583\n",
      "United_States\n",
      " 0.005411\n",
      "2008\n",
      " 0.005085\n",
      "France\n",
      " 0.004673\n",
      "United_Kingdom\n",
      " 0.004544\n"
     ]
    }
   ],
   "source": [
    "eigen_value = np.real(eigen_value)\n",
    "\n",
    "alpha = (0.85*(1/abs(eigen_value)))\n",
    "num_nodes = len(titles.keys())\n",
    "\n",
    "I = np.identity(num_nodes)\n",
    "u = np.ones(num_nodes)\n",
    "\n",
    "A = sparse_matrix.toarray()\n",
    "\n",
    "te = (I-alpha*A)\n",
    "\n",
    "inverted = np.linalg.inv(te)\n",
    "\n",
    "centrality_vector = (1/num_nodes)*inverted@u\n",
    "centrality_vector /= centrality_vector.sum()\n",
    "\n",
    "sorted_katz = np.argsort(centrality_vector)[::-1]\n",
    "\n",
    "# Get the values and indices of the first 5 elements\n",
    "katz_top5 = centrality_vector[sorted_katz[:5]]\n",
    "top5_eigen_indices = sorted_katz[:5]\n",
    "for i in sorted_katz[:5]:\n",
    "    print(titles[i+1], round(centrality_vector[i],6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portugal\n",
      " 0.012437\n",
      "United_States\n",
      " 0.012286\n",
      "2007\n",
      " 0.010234\n",
      "2008\n",
      " 0.00812\n",
      "Wikimedia_Commons\n",
      " 0.00697\n"
     ]
    }
   ],
   "source": [
    "cop = num_degrees_out.copy()\n",
    "kout = []\n",
    "for i in range(1, num_nodes+1):\n",
    "    if(i not in cop.keys()):\n",
    "        kout.append(0)\n",
    "    else:\n",
    "        kout.append(1/cop[i])\n",
    "H = A * kout\n",
    "alpha = 0.85\n",
    "u = np.ones(num_nodes)\n",
    "I = np.identity(num_nodes)\n",
    "aH = alpha*H\n",
    "inverted = np.linalg.inv(I-aH)\n",
    "closed_gp = ((1-alpha)/num_nodes)*inverted@u\n",
    "closed_gp /= closed_gp.sum()\n",
    "\n",
    "sorted_closed_gp = np.argsort(closed_gp)[::-1]\n",
    "\n",
    "for i in sorted_closed_gp[:5]:\n",
    "    print(titles[i+1], round(closed_gp[i],6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max PageRank Score: 0.009918460504093606\n",
      "United_States\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009918"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = A * kout\n",
    "\n",
    "for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "        if(A[i][j] == 0 and kout[j]==0):\n",
    "            H[i][j] = 1/num_nodes\n",
    "\n",
    "alpha = 0.85\n",
    "uut = np.ones((num_nodes, num_nodes))\n",
    "G = alpha * H + ((1 - alpha) / num_nodes) * uut\n",
    "\n",
    "initial_guess = np.ones(num_nodes) / num_nodes\n",
    "num_iterations = 1\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    initial_guess = G @ initial_guess\n",
    "    initial_guess /= initial_guess.sum()\n",
    "\n",
    "# Normalize once after the loop\n",
    "initial_guess /= initial_guess.sum()\n",
    "\n",
    "print(\"Max PageRank Score:\", np.max(initial_guess))\n",
    "max_index = np.argmax(initial_guess)\n",
    "\n",
    "print(titles[max_index+1])\n",
    "0.009918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18828/3333531932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mpagerank_iterative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mpagerank_iterative\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0muut\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mportugal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpagerank_iterative\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_three_articles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0munited_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpagerank_iterative\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_three_articles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Lists to store evolution of PageRank scores over iterations\n",
    "top_three_articles = sorted_closed_gp[:3]\n",
    "pagerank_iterative = np.ones(num_nodes) / num_nodes\n",
    "evolution_iterative = []\n",
    "\n",
    "portugal = []\n",
    "united_states = []\n",
    "val_2007 = []\n",
    "\n",
    "# Perform iterative PageRank calculation\n",
    "num_iterations = 100\n",
    "for iteration in range(num_iterations):\n",
    "    pagerank_iterative = alpha * (H @ pagerank_iterative) + ((1 - alpha) / num_nodes)\n",
    "    portugal.append(pagerank_iterative[top_three_articles[0]])\n",
    "    united_states.append(pagerank_iterative[top_three_articles[1]])\n",
    "    val_2007.append(pagerank_iterative[top_three_articles[2]])\n",
    "\n",
    "#portugal /= np.array(portugal).sum()\n",
    "#united_states /= np.array(united_states).sum()\n",
    "#val_2007 /= np.array(val_2007).sum()\n",
    "\n",
    "print(portugal[99])\n",
    "print(united_states[99])\n",
    "print(val_2007[99])\n",
    "\n",
    "iterations = np.arange(0, num_iterations)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, portugal, label=\"Portugal\")\n",
    "plt.plot(iterations, united_states, label=\"United States\")\n",
    "plt.plot(iterations, val_2007, label=\"2007\")\n",
    "plt.title(\"Evolution of PageRank Scores for Top-Three Articles\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"PageRank Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "start = np.ones(num_nodes) / num_nodes\n",
    "alpha = 0.85\n",
    "\n",
    "iterations_values = []\n",
    "for n in range(num_nodes):\n",
    "    first_sum = 0\n",
    "    second_sum = 0\n",
    "    for nprime in range(num_nodes):\n",
    "        ann = A[n][nprime]\n",
    "        k = kout[nprime]\n",
    "        cent = start[nprime]\n",
    "        if(k == 0 and ann == 0):\n",
    "            k = 1/num_nodes\n",
    "        elif(k == 0):\n",
    "            print(\"error\")\n",
    "        first_sum+=((ann/k)*cent)\n",
    "        second_sum+=(cent)\n",
    "    one_iteration = alpha * (first_sum) + ((1 - alpha) / num_nodes)*second_sum\n",
    "    iterations_values.append(one_iteration)\n",
    "\n",
    "\n",
    "\n",
    "print(np.argmax(iterations_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2197 2770   71   73 2899]\n",
      "2007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sorted_closed_gp[:5])\n",
    "print(titles[72])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
